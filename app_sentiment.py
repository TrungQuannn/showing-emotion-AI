import streamlit as st
import pandas as pd
import joblib
import pickle
from underthesea import word_tokenize
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

# -----------------------------
# ğŸ”§ Cáº¥u hÃ¬nh file dá»¯ liá»‡u
# -----------------------------
DATA_FILE = "sentiment_data.csv"
MODEL_FILE = "sentiment_model.pkl"
VECTORIZER_FILE = "vectorizer.pkl"

# -----------------------------
# ğŸ“¦ Load hoáº·c táº¡o má»›i dá»¯ liá»‡u
# -----------------------------
def load_data():
    try:
        df = pd.read_csv(DATA_FILE)
    except FileNotFoundError:
        df = pd.DataFrame({"text": [], "label": []})
        df.to_csv(DATA_FILE, index=False)
    return df

# -----------------------------
# ğŸ§  Load hoáº·c táº¡o má»›i mÃ´ hÃ¬nh
# -----------------------------
def load_model():
    try:
        with open(MODEL_FILE, "rb") as f:
            obj = pickle.load(f)
            if isinstance(obj, tuple) and len(obj) == 2:
                model, vectorizer = obj
            else:
                model = joblib.load(MODEL_FILE)
                vectorizer = joblib.load(VECTORIZER_FILE)
    except:
        df = load_data()
        if len(df) > 0:
            vectorizer = CountVectorizer()
            X = vectorizer.fit_transform(df["text"])
            y = df["label"]
            model = MultinomialNB()
            model.fit(X, y)
            with open(MODEL_FILE, "wb") as f:
                pickle.dump((model, vectorizer), f)
        else:
            vectorizer = CountVectorizer()
            model = MultinomialNB()
    return model, vectorizer

# -----------------------------
# ğŸš€ Giao diá»‡n Streamlit
# -----------------------------
st.set_page_config(page_title="Sentiment Trainer ğŸ‡»ğŸ‡³", page_icon="ğŸ’¬", layout="centered")
st.title("ğŸ‡»ğŸ‡³ AI PhÃ¢n Loáº¡i Cáº£m XÃºc Tiáº¿ng Viá»‡t ğŸ˜„ğŸ˜ğŸ˜")
st.write("AI sáº½ há»c cáº£m xÃºc tiáº¿ng Viá»‡t tá»« chÃ­nh báº¡n â€” dáº¡y nÃ³ thÃªm khi nÃ³ chÆ°a biáº¿t nhÃ©!")

# Load dá»¯ liá»‡u & mÃ´ hÃ¬nh
df = load_data()
model, vectorizer = load_model()

# -----------------------------
# âœï¸ Nháº­p cÃ¢u cáº§n phÃ¢n tÃ­ch
# -----------------------------
user_text = st.text_input("Nháº­p cÃ¢u hoáº·c tá»« tiáº¿ng Viá»‡t:")

if user_text:
    processed = word_tokenize(user_text, format="text")

    # Kiá»ƒm tra xem cÃ³ tá»« nÃ o chÆ°a há»c khÃ´ng
    unknown_words = [w for w in processed.split() if w not in vectorizer.vocabulary_]

    if len(unknown_words) > 0:
        st.warning(f"ğŸ¤” TÃ´i chÆ°a há»c qua {len(unknown_words)} tá»«: {', '.join(unknown_words)}.")
        st.info("Báº¡n cÃ³ muá»‘n dáº¡y tÃ´i biáº¿t cáº£m xÃºc cá»§a tá»«/cÃ¢u nÃ y khÃ´ng?")

        label = st.radio("GÃ¡n nhÃ£n cáº£m xÃºc:", ["positive", "negative", "neutral"], horizontal=True)
        if st.button("ğŸ’¾ LÆ°u tá»« má»›i"):
            new_row = pd.DataFrame([[processed, label]], columns=["text", "label"])
            df = pd.concat([df, new_row], ignore_index=True)
            df.to_csv(DATA_FILE, index=False)
            st.success(f"âœ… ÄÃ£ lÆ°u tá»« má»›i: '{user_text}' â†’ {label}.")
            st.balloons()
            st.info("ğŸ’¡ TÃ´i sáº½ biáº¿t nghÄ©a tá»« nÃ y sau khi báº¡n báº¥m 'Huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh'.")
    else:
        # Náº¿u táº¥t cáº£ tá»« Ä‘Ã£ há»c, thÃ¬ dá»± Ä‘oÃ¡n cáº£m xÃºc
        try:
            X_input = vectorizer.transform([processed])
            pred = model.predict(X_input)[0]
            if pred == "positive":
                emoji = "ğŸ˜Š"
            elif pred == "negative":
                emoji = "ğŸ˜"
            else:
                emoji = "ğŸ˜"
            st.subheader(f"ğŸ” Káº¿t quáº£ dá»± Ä‘oÃ¡n: **{pred.upper()}** {emoji}")
        except Exception:
            st.warning("âš ï¸ MÃ´ hÃ¬nh chÆ°a Ä‘á»§ dá»¯ liá»‡u. HÃ£y thÃªm vÃ­ dá»¥ vÃ  huáº¥n luyá»‡n láº¡i.")

# -----------------------------
# ğŸ” Huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh
# -----------------------------
st.write("---")
if st.button("ğŸ” Huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh"):
    df = load_data()
    if len(df) < 3:
        st.warning("âš ï¸ Cáº§n Ã­t nháº¥t 3 máº«u Ä‘á»ƒ huáº¥n luyá»‡n.")
    else:
        vectorizer = CountVectorizer()
        X = vectorizer.fit_transform(df["text"])
        y = df["label"]
        model = MultinomialNB()
        model.fit(X, y)
        with open(MODEL_FILE, "wb") as f:
            pickle.dump((model, vectorizer), f)
        joblib.dump(vectorizer, VECTORIZER_FILE)
        st.success("âœ… Ã€, tÃ´i biáº¿t nghÄ©a cá»§a cÃ¡c tá»« má»›i rá»“i! Cáº£m Æ¡n báº¡n Ä‘Ã£ dáº¡y tÃ´i â¤ï¸")

# -----------------------------
# ğŸ“Š Hiá»ƒn thá»‹ dá»¯ liá»‡u hiá»‡n cÃ³
# -----------------------------
st.write("---")
st.subheader("ğŸ“‚ Dá»¯ liá»‡u huáº¥n luyá»‡n hiá»‡n táº¡i:")
st.dataframe(df.tail(10))

st.caption("ğŸ’¡ HÃ£y thá»­ nháº­p: 'TÃ´i vui quÃ¡' (positive), 'TÃ´i chÃ¡n láº¯m' (negative), hoáº·c 'TÃ´i Ä‘ang há»c' (neutral).")
