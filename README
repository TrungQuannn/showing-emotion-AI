 Giá»›i thiá»‡u vá» code
1ï¸âƒ£ Ã tÆ°á»Ÿng

Má»¥c tiÃªu cá»§a dá»± Ã¡n lÃ  xÃ¢y dá»±ng má»™t AI cÃ³ kháº£ nÄƒng hiá»ƒu vÃ  há»c cáº£m xÃºc tiáº¿ng Viá»‡t, cá»¥ thá»ƒ:

Nháº­n diá»‡n cÃ¢u mang cáº£m xÃºc tÃ­ch cá»±c (positive), tiÃªu cá»±c (negative) hoáº·c trung tÃ­nh (neutral).

CÃ³ kháº£ nÄƒng tá»± há»c â€” ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ dáº¡y trá»±c tiáº¿p cho AI khi gáº·p tá»«/cÃ¢u chÆ°a biáº¿t.

ğŸ‘‰ NÃ³i cÃ¡ch khÃ¡c, Ä‘Ã¢y lÃ  má»™t há»‡ thá»‘ng AI â€œtá»± há»c cáº£m xÃºcâ€, vá»«a phÃ¢n tÃ­ch Ä‘Æ°á»£c cáº£m xÃºc, vá»«a tiáº¿p thu thÃªm kiáº¿n thá»©c má»›i mÃ  ngÆ°á»i dÃ¹ng gÃ¡n nhÃ£n cho.
---
2ï¸âƒ£ CÃ i Ä‘áº·t mÃ´i trÆ°á»ng
a. YÃªu cáº§u ban Ä‘áº§u

Python >= 3.9

Pip (trÃ¬nh quáº£n lÃ½ gÃ³i cá»§a Python)

Há»‡ Ä‘iá»u hÃ nh: Windows / macOS / Linux

b. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng áº£o (khuyÃªn dÃ¹ng)

Windows:

python -m venv venv
venv\Scripts\activate


macOS / Linux:

python3 -m venv venv
source venv/bin/activate

c. CÃ i Ä‘áº·t thÆ° viá»‡n cáº§n thiáº¿t
pip install pandas scikit-learn matplotlib seaborn underthesea streamlit joblib
3/ Xá»­ lÃ­ code:

a/ train_sentiment.py: code hÃ¬nh thÃ nh model cÆ¡ báº£n
Chá»©c nÄƒng:

Táº¡o bá»™ dá»¯ liá»‡u máº«u ban Ä‘áº§u.
Tokenize (xá»­ lÃ½ tá»« vá»±ng tiáº¿ng Viá»‡t).
Huáº¥n luyá»‡n mÃ´ hÃ¬nh Logistic Regression Ä‘á»ƒ phÃ¢n loáº¡i cáº£m xÃºc.
ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c, hiá»ƒn thá»‹ confusion matrix.
LÆ°u mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n thÃ nh tá»‡p .pkl.
Sau khi cháº¡y file nÃ y, báº¡n sáº½ cÃ³ 2 tá»‡p:
sentiment_model.pkl vÃ  vectorizer.pkl


CODE:

import pandas as pd
from underthesea import word_tokenize
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import pickle
import matplotlib.pyplot as plt
import seaborn as sns

# ====== 1. Dá»¯ liá»‡u máº«u ======
data = {
    "text": [
        "HÃ´m nay tÃ´i ráº¥t vui",
        "Trá»i Ä‘áº¹p quÃ¡, tÃ´i cáº£m tháº¥y háº¡nh phÃºc",
        "TÃ´i ghÃ©t pháº£i chá» Ä‘á»£i",
        "Tháº­t tá»‡, tÃ´i má»‡t vÃ  buá»“n",
        "ThÃ nh cÃ´ng rá»“i! Tuyá»‡t vá»i quÃ¡",
        "TÃ´i tháº¥y chÃ¡n vÃ  tháº¥t vá»ng",
        "Cáº£m Æ¡n báº¡n, tÃ´i ráº¥t hÃ i lÃ²ng",
        "Dá»‹ch vá»¥ quÃ¡ tá»‡, khÃ´ng Ä‘Ã¡ng tiá»n",
        "CÃ¡i bÃ n nÃ y mÃ u xanh",
        "TÃ´i Ä‘ang ngá»“i há»c",
        "ChÃºng sinh Ä‘au buá»“n",
        "Cáº£ lá»›p cÃ¹ng cÆ°á»i vui váº»"
    ],
    "label": [
        "positive", "positive", "negative", "negative",
        "positive", "negative", "positive", "negative",
        "neutral", "neutral", "negative", "positive"
    ]
}

df = pd.DataFrame(data)

# ====== 2. Tiá»n xá»­ lÃ½ ======
df["text"] = df["text"].apply(lambda x: word_tokenize(x, format="text"))

X_train, X_test, y_train, y_test = train_test_split(df["text"], df["label"], test_size=0.25, random_state=42)

vectorizer = CountVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# ====== 3. Huáº¥n luyá»‡n ======
model = LogisticRegression(max_iter=200)
model.fit(X_train_vec, y_train)

# ====== 4. ÄÃ¡nh giÃ¡ ======
y_pred = model.predict(X_test_vec)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

# Váº½ confusion matrix
cm = confusion_matrix(y_test, y_pred, labels=["positive", "negative", "neutral"])
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=["positive", "negative", "neutral"],
            yticklabels=["positive", "negative", "neutral"])
plt.title("Confusion Matrix - 3 Cáº£m XÃºc")
plt.show()

# ====== 5. LÆ°u model ======
with open("sentiment_model.pkl", "wb") as f:
    pickle.dump((model, vectorizer), f)
print("âœ… ÄÃ£ lÆ°u model sentiment_model.pkl (3 cáº£m xÃºc)")



b/ app_sentiment.py: giao diá»‡n
Nháº­p cÃ¢u Ä‘á»ƒ AI dá»± Ä‘oÃ¡n cáº£m xÃºc
Náº¿u AI â€œchÆ°a hiá»ƒuâ€ cÃ¢u Ä‘Ã³, ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ gÃ¡n nhÃ£n cáº£m xÃºc cho cÃ¢u Ä‘Ã³ vÃ  lÆ°u láº¡i.
Nháº¥n nÃºt â€œHuáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nhâ€ Ä‘á»ƒ AI há»c tá»« dá»¯ liá»‡u má»›i.
Xem báº£ng dá»¯ liá»‡u huáº¥n luyá»‡n hiá»‡n cÃ³.

CODE:

import streamlit as st
import pandas as pd
import joblib
import pickle
from underthesea import word_tokenize
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

# -----------------------------
# ğŸ”§ Cáº¥u hÃ¬nh file dá»¯ liá»‡u
# -----------------------------
DATA_FILE = "sentiment_data.csv"
MODEL_FILE = "sentiment_model.pkl"
VECTORIZER_FILE = "vectorizer.pkl"

# -----------------------------
# ğŸ“¦ Load hoáº·c táº¡o má»›i dá»¯ liá»‡u
# -----------------------------
def load_data():
    try:
        df = pd.read_csv(DATA_FILE)
    except FileNotFoundError:
        df = pd.DataFrame({"text": [], "label": []})
        df.to_csv(DATA_FILE, index=False)
    return df

# -----------------------------
# ğŸ§  Load hoáº·c táº¡o má»›i mÃ´ hÃ¬nh
# -----------------------------
def load_model():
    try:
        with open(MODEL_FILE, "rb") as f:
            obj = pickle.load(f)
            if isinstance(obj, tuple) and len(obj) == 2:
                model, vectorizer = obj
            else:
                model = joblib.load(MODEL_FILE)
                vectorizer = joblib.load(VECTORIZER_FILE)
    except:
        df = load_data()
        if len(df) > 0:
            vectorizer = CountVectorizer()
            X = vectorizer.fit_transform(df["text"])
            y = df["label"]
            model = MultinomialNB()
            model.fit(X, y)
            with open(MODEL_FILE, "wb") as f:
                pickle.dump((model, vectorizer), f)
        else:
            vectorizer = CountVectorizer()
            model = MultinomialNB()
    return model, vectorizer

# -----------------------------
# ğŸš€ Giao diá»‡n Streamlit
# -----------------------------
st.set_page_config(page_title="Sentiment Trainer ğŸ‡»ğŸ‡³", page_icon="ğŸ’¬", layout="centered")
st.title("ğŸ‡»ğŸ‡³ AI PhÃ¢n Loáº¡i Cáº£m XÃºc Tiáº¿ng Viá»‡t ğŸ˜„ğŸ˜ğŸ˜")
st.write("AI sáº½ há»c cáº£m xÃºc tiáº¿ng Viá»‡t tá»« chÃ­nh báº¡n â€” dáº¡y nÃ³ thÃªm khi nÃ³ chÆ°a biáº¿t nhÃ©!")

# Load dá»¯ liá»‡u & mÃ´ hÃ¬nh
df = load_data()
model, vectorizer = load_model()

# -----------------------------
# âœï¸ Nháº­p cÃ¢u cáº§n phÃ¢n tÃ­ch
# -----------------------------
user_text = st.text_input("Nháº­p cÃ¢u hoáº·c tá»« tiáº¿ng Viá»‡t:")

if user_text:
    processed = word_tokenize(user_text, format="text")

    # Kiá»ƒm tra xem cÃ³ tá»« nÃ o chÆ°a há»c khÃ´ng
    unknown_words = [w for w in processed.split() if w not in vectorizer.vocabulary_]

    if len(unknown_words) > 0:
        st.warning(f"ğŸ¤” TÃ´i chÆ°a há»c qua {len(unknown_words)} tá»«: {', '.join(unknown_words)}.")
        st.info("Báº¡n cÃ³ muá»‘n dáº¡y tÃ´i biáº¿t cáº£m xÃºc cá»§a tá»«/cÃ¢u nÃ y khÃ´ng?")

        label = st.radio("GÃ¡n nhÃ£n cáº£m xÃºc:", ["positive", "negative", "neutral"], horizontal=True)
        if st.button("ğŸ’¾ LÆ°u tá»« má»›i"):
            new_row = pd.DataFrame([[processed, label]], columns=["text", "label"])
            df = pd.concat([df, new_row], ignore_index=True)
            df.to_csv(DATA_FILE, index=False)
            st.success(f"âœ… ÄÃ£ lÆ°u tá»« má»›i: '{user_text}' â†’ {label}.")
            st.balloons()
            st.info("ğŸ’¡ TÃ´i sáº½ biáº¿t nghÄ©a tá»« nÃ y sau khi báº¡n báº¥m 'Huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh'.")
    else:
        # Náº¿u táº¥t cáº£ tá»« Ä‘Ã£ há»c, thÃ¬ dá»± Ä‘oÃ¡n cáº£m xÃºc
        try:
            X_input = vectorizer.transform([processed])
            pred = model.predict(X_input)[0]
            if pred == "positive":
                emoji = "ğŸ˜Š"
            elif pred == "negative":
                emoji = "ğŸ˜"
            else:
                emoji = "ğŸ˜"
            st.subheader(f"ğŸ” Káº¿t quáº£ dá»± Ä‘oÃ¡n: **{pred.upper()}** {emoji}")
        except Exception:
            st.warning("âš ï¸ MÃ´ hÃ¬nh chÆ°a Ä‘á»§ dá»¯ liá»‡u. HÃ£y thÃªm vÃ­ dá»¥ vÃ  huáº¥n luyá»‡n láº¡i.")

# -----------------------------
# ğŸ” Huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh
# -----------------------------
st.write("---")
if st.button("ğŸ” Huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh"):
    df = load_data()
    if len(df) < 3:
        st.warning("âš ï¸ Cáº§n Ã­t nháº¥t 3 máº«u Ä‘á»ƒ huáº¥n luyá»‡n.")
    else:
        vectorizer = CountVectorizer()
        X = vectorizer.fit_transform(df["text"])
        y = df["label"]
        model = MultinomialNB()
        model.fit(X, y)
        with open(MODEL_FILE, "wb") as f:
            pickle.dump((model, vectorizer), f)
        joblib.dump(vectorizer, VECTORIZER_FILE)
        st.success("âœ… Ã€, tÃ´i biáº¿t nghÄ©a cá»§a cÃ¡c tá»« má»›i rá»“i! Cáº£m Æ¡n báº¡n Ä‘Ã£ dáº¡y tÃ´i â¤ï¸")

# -----------------------------
# ğŸ“Š Hiá»ƒn thá»‹ dá»¯ liá»‡u hiá»‡n cÃ³
# -----------------------------
st.write("---")
st.subheader("ğŸ“‚ Dá»¯ liá»‡u huáº¥n luyá»‡n hiá»‡n táº¡i:")
st.dataframe(df.tail(10))

st.caption("ğŸ’¡ HÃ£y thá»­ nháº­p: 'TÃ´i vui quÃ¡' (positive), 'TÃ´i chÃ¡n láº¯m' (negative), hoáº·c 'TÃ´i Ä‘ang há»c' (neutral).")


Káº¿t quáº£ thÃªmL cÃ³ 2 file. csv Ä‘Æ°á»£c Ä‘áº¡o


4/ Cháº¡y vÃ  kiá»ƒm thá»­

bÆ°á»›c 1: Huáº¥n luyá»‡n ban Ä‘áº§u:
python train_sentiment.py (cháº¡y á»Ÿ bash terminal)
==> nÃ³ sáº½ ra 1 file "Sentiment_model.pkl", "vectorizer.pkl", kÃ¨m vá»›i 1 biá»ƒu Ä‘á»“ ban Ä‘áº§u cho mÃ´ hÃ¬nh cÃ³ sáºµn

bÆ°á»›c 2: cháº¡y web:
á»Ÿ Ä‘Ã¢y, cÃ¡c báº¡n cÃ³ 2 cÃ¡ch cháº¡y:
+ cháº¡y trong vscode: Nháº¥n run vÃ  nÃ³ ra má»™t textbox nhá» Ä‘á»ƒ lÃ m viá»‡c
(tÆ°Æ¡ng tá»± nhÆ° cÃ¡i báº£ng sudoku á»Ÿ topic Optimization)
+ cháº¡y web: VÃ o bash terminal, gÃµ:

"streamlit run app_sentiment.py" ==> giao diá»‡n streamlit
lÃºc nÃ y, nÃ³ sáº½ ra link localhost, nháº¥n vÃ o vÃ  thá»­ nghiá»‡m

5/ cÃ¡ch sá»­ dá»¥ng trong giao diá»‡n: NÃ³ sáº½ kiá»ƒm thá»­ text báº¡n nháº­p: 
+ positive/ negative/neutral: nÃ³ lÃ  tháº¿ Ä‘áº¥y
+ báº£o ráº±ng khÃ´ng biáº¿t tá»« nÃ y:
chÆ°a cÃ³ trong model, vÃ  cáº§n báº¡n train

CÃ¡ch train: dÃ¡n nhÃ¡n tá»« Ä‘Ã³ => lÆ°u => cháº¡y láº¡i mÃ´ hÃ¬nh



