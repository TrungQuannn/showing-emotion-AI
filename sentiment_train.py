import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pickle

from underthesea import word_tokenize
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score


# ================================================
# 1ï¸âƒ£ Dá»® LIá»†U MáºªU BAN Äáº¦U
# ================================================
data = {
    "text": [
        "HÃ´m nay tÃ´i ráº¥t vui",
        "Trá»i Ä‘áº¹p quÃ¡, tÃ´i cáº£m tháº¥y háº¡nh phÃºc",
        "TÃ´i ghÃ©t pháº£i chá» Ä‘á»£i",
        "Tháº­t tá»‡, tÃ´i má»‡t vÃ  buá»“n",
        "ThÃ nh cÃ´ng rá»“i! Tuyá»‡t vá»i quÃ¡",
        "TÃ´i tháº¥y chÃ¡n vÃ  tháº¥t vá»ng",
        "Cáº£m Æ¡n báº¡n, tÃ´i ráº¥t hÃ i lÃ²ng",
        "Dá»‹ch vá»¥ quÃ¡ tá»‡, khÃ´ng Ä‘Ã¡ng tiá»n",
        "CÃ¡i bÃ n nÃ y mÃ u xanh",
        "TÃ´i Ä‘ang ngá»“i há»c",
        "ChÃºng sinh Ä‘au buá»“n",
        "Cáº£ lá»›p cÃ¹ng cÆ°á»i vui váº»"
    ],
    "label": [
        "positive", "positive", "negative", "negative",
        "positive", "negative", "positive", "negative",
        "neutral", "neutral", "negative", "positive"
    ]
}

df = pd.DataFrame(data)
print(f"ğŸ“˜ Dá»¯ liá»‡u ban Ä‘áº§u: {len(df)} máº«u\n")

# ================================================
# 2ï¸âƒ£ TIá»€N Xá»¬ LÃ NGÃ”N NGá»®
# ================================================
print("ğŸ”§ Äang tiá»n xá»­ lÃ½ vÄƒn báº£n...")

# TÃ¡ch tá»« tiáº¿ng Viá»‡t
df["text"] = df["text"].apply(lambda x: word_tokenize(x, format="text"))

# TÃ¡ch táº­p train/test
X_train, X_test, y_train, y_test = train_test_split(
    df["text"], df["label"], test_size=0.25, random_state=42
)

# Vector hÃ³a vÄƒn báº£n
vectorizer = CountVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

print(f"âœ… Sá»‘ Ä‘áº·c trÆ°ng (features): {len(vectorizer.get_feature_names_out())}")

# ================================================
# 3ï¸âƒ£ HUáº¤N LUYá»†N MÃ” HÃŒNH
# ================================================
print("\nğŸš€ Báº¯t Ä‘áº§u huáº¥n luyá»‡n mÃ´ hÃ¬nh Logistic Regression...")
model = LogisticRegression(max_iter=200, solver='lbfgs')
model.fit(X_train_vec, y_train)

print("âœ… Huáº¥n luyá»‡n hoÃ n táº¥t!")

# ================================================
# 4ï¸âƒ£ ÄÃNH GIÃ HIá»†U SUáº¤T
# ================================================
print("\nğŸ“Š ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh:")

y_pred = model.predict(X_test_vec)
acc = accuracy_score(y_test, y_pred)

print(f"ğŸ¯ Accuracy: {acc:.2%}")
print(classification_report(y_test, y_pred, digits=3))

# Hiá»ƒn thá»‹ confusion matrix
cm = confusion_matrix(y_test, y_pred, labels=["positive", "negative", "neutral"])
plt.figure(figsize=(6, 4))
sns.heatmap(
    cm, annot=True, fmt='d', cmap='Blues',
    xticklabels=["positive", "negative", "neutral"],
    yticklabels=["positive", "negative", "neutral"]
)
plt.title("Confusion Matrix - MÃ´ hÃ¬nh phÃ¢n tÃ­ch cáº£m xÃºc (3 lá»›p)")
plt.xlabel("Dá»± Ä‘oÃ¡n")
plt.ylabel("Thá»±c táº¿")
plt.tight_layout()
plt.show()

# ================================================
# 5ï¸âƒ£ LÆ¯U MÃ” HÃŒNH & VECTORIZER
# ================================================
MODEL_FILE = "sentiment_model.pkl"

with open(MODEL_FILE, "wb") as f:
    pickle.dump((model, vectorizer), f)

print(f"\nğŸ’¾ ÄÃ£ lÆ°u mÃ´ hÃ¬nh vÃ o: {MODEL_FILE}")
print("ğŸ QuÃ¡ trÃ¬nh huáº¥n luyá»‡n hoÃ n táº¥t thÃ nh cÃ´ng!")
